{"ast":null,"code":"import { normalizeLogicalComposition } from './logical';\nimport { normalizePredicate } from './predicate';\nimport { hasProperty } from './util';\nexport function isFilter(t) {\n  return hasProperty(t, 'filter');\n}\nexport function isImputeSequence(t) {\n  return hasProperty(t, 'stop');\n}\nexport function isLookup(t) {\n  return hasProperty(t, 'lookup');\n}\nexport function isLookupData(from) {\n  return hasProperty(from, 'data');\n}\nexport function isLookupSelection(from) {\n  return hasProperty(from, 'param');\n}\nexport function isPivot(t) {\n  return hasProperty(t, 'pivot');\n}\nexport function isDensity(t) {\n  return hasProperty(t, 'density');\n}\nexport function isQuantile(t) {\n  return hasProperty(t, 'quantile');\n}\nexport function isRegression(t) {\n  return hasProperty(t, 'regression');\n}\nexport function isLoess(t) {\n  return hasProperty(t, 'loess');\n}\nexport function isSample(t) {\n  return hasProperty(t, 'sample');\n}\nexport function isWindow(t) {\n  return hasProperty(t, 'window');\n}\nexport function isJoinAggregate(t) {\n  return hasProperty(t, 'joinaggregate');\n}\nexport function isFlatten(t) {\n  return hasProperty(t, 'flatten');\n}\nexport function isCalculate(t) {\n  return hasProperty(t, 'calculate');\n}\nexport function isBin(t) {\n  return hasProperty(t, 'bin');\n}\nexport function isImpute(t) {\n  return hasProperty(t, 'impute');\n}\nexport function isTimeUnit(t) {\n  return hasProperty(t, 'timeUnit');\n}\nexport function isAggregate(t) {\n  return hasProperty(t, 'aggregate');\n}\nexport function isStack(t) {\n  return hasProperty(t, 'stack');\n}\nexport function isFold(t) {\n  return hasProperty(t, 'fold');\n}\nexport function isExtent(t) {\n  return hasProperty(t, 'extent') && !hasProperty(t, 'density') && !hasProperty(t, 'regression');\n}\nexport function normalizeTransform(transform) {\n  return transform.map(t => {\n    if (isFilter(t)) {\n      return {\n        filter: normalizeLogicalComposition(t.filter, normalizePredicate)\n      };\n    }\n    return t;\n  });\n}","map":{"version":3,"names":["normalizeLogicalComposition","normalizePredicate","hasProperty","isFilter","t","isImputeSequence","isLookup","isLookupData","from","isLookupSelection","isPivot","isDensity","isQuantile","isRegression","isLoess","isSample","isWindow","isJoinAggregate","isFlatten","isCalculate","isBin","isImpute","isTimeUnit","isAggregate","isStack","isFold","isExtent","normalizeTransform","transform","map","filter"],"sources":["C:\\Users\\sutul\\node_modules\\vega-lite\\src\\transform.ts"],"sourcesContent":["import type {AggregateOp} from 'vega';\nimport {BinParams} from './bin';\nimport {FieldName} from './channeldef';\nimport {Data} from './data';\nimport {ImputeParams} from './impute';\nimport {LogicalComposition, normalizeLogicalComposition} from './logical';\nimport {ParameterName} from './parameter';\nimport {normalizePredicate, Predicate} from './predicate';\nimport {SortField} from './sort';\nimport {TimeUnit, TimeUnitTransformParams} from './timeunit';\nimport {hasProperty} from './util';\n\nexport interface FilterTransform {\n  /**\n   * The `filter` property must be a predication definition, which can take one of the following forms:\n   *\n   * 1) an [expression](https://vega.github.io/vega-lite/docs/types.html#expression) string,\n   * where `datum` can be used to refer to the current data object.\n   * For example, `{filter: \"datum.b2 > 60\"}` would make the output data includes only items that have values in the field `b2` over 60.\n   *\n   * 2) one of the [field predicates](https://vega.github.io/vega-lite/docs/predicate.html#field-predicate):\n   * [`equal`](https://vega.github.io/vega-lite/docs/predicate.html#field-equal-predicate),\n   * [`lt`](https://vega.github.io/vega-lite/docs/predicate.html#lt-predicate),\n   * [`lte`](https://vega.github.io/vega-lite/docs/predicate.html#lte-predicate),\n   * [`gt`](https://vega.github.io/vega-lite/docs/predicate.html#gt-predicate),\n   * [`gte`](https://vega.github.io/vega-lite/docs/predicate.html#gte-predicate),\n   * [`range`](https://vega.github.io/vega-lite/docs/predicate.html#range-predicate),\n   * [`oneOf`](https://vega.github.io/vega-lite/docs/predicate.html#one-of-predicate),\n   * or [`valid`](https://vega.github.io/vega-lite/docs/predicate.html#valid-predicate),\n\n   * 3) a [selection predicate](https://vega.github.io/vega-lite/docs/predicate.html#selection-predicate), which define the names of a selection that the data point should belong to (or a logical composition of selections).\n   *\n   * 4) a [logical composition](https://vega.github.io/vega-lite/docs/predicate.html#composition) of (1), (2), or (3).\n   */\n  filter: LogicalComposition<Predicate>;\n}\n\nexport function isFilter(t: Transform): t is FilterTransform {\n  return hasProperty(t, 'filter');\n}\n\nexport interface CalculateTransform {\n  /**\n   * A [expression](https://vega.github.io/vega-lite/docs/types.html#expression) string. Use the variable `datum` to refer to the current data object.\n   */\n  calculate: string;\n\n  /**\n   * The field for storing the computed formula value.\n   */\n  as: FieldName;\n}\n\nexport interface BinTransform {\n  /**\n   * An object indicating bin properties, or simply `true` for using default bin parameters.\n   */\n  bin: true | BinParams;\n\n  /**\n   * The data field to bin.\n   */\n  field: FieldName;\n\n  /**\n   * The output fields at which to write the start and end bin values.\n   * This can be either a string or an array of strings with two elements denoting the name for the fields for bin start and bin end respectively.\n   * If a single string (e.g., `\"val\"`) is provided, the end field will be `\"val_end\"`.\n   */\n  as: FieldName | FieldName[];\n}\n\nexport interface TimeUnitTransform {\n  /**\n   * The timeUnit.\n   */\n  timeUnit: TimeUnit | TimeUnitTransformParams;\n\n  /**\n   * The data field to apply time unit.\n   */\n  field: FieldName;\n\n  /**\n   * The output field to write the timeUnit value.\n   */\n  as: FieldName;\n}\n\nexport interface AggregateTransform {\n  /**\n   * Array of objects that define fields to aggregate.\n   */\n  aggregate: AggregatedFieldDef[];\n\n  /**\n   * The data fields to group by. If not specified, a single group containing all data objects will be used.\n   */\n  groupby?: FieldName[];\n}\n\nexport interface AggregatedFieldDef {\n  /**\n   * The aggregation operation to apply to the fields (e.g., `\"sum\"`, `\"average\"`, or `\"count\"`).\n   * See the [full list of supported aggregation operations](https://vega.github.io/vega-lite/docs/aggregate.html#ops)\n   * for more information.\n   */\n  op: AggregateOp;\n\n  /**\n   * The data field for which to compute aggregate function. This is required for all aggregation operations except `\"count\"`.\n   */\n  field?: FieldName;\n\n  /**\n   * The output field names to use for each aggregated field.\n   */\n  as: FieldName;\n}\n\nexport interface StackTransform {\n  /**\n   * The field which is stacked.\n   */\n  stack: FieldName;\n  /**\n   * The data fields to group by.\n   */\n  groupby: FieldName[];\n  /**\n   * Mode for stacking marks. One of `\"zero\"` (default), `\"center\"`, or `\"normalize\"`.\n   * The `\"zero\"` offset will stack starting at `0`. The `\"center\"` offset will center the stacks. The `\"normalize\"` offset will compute percentage values for each stack point, with output values in the range `[0,1]`.\n   *\n   * __Default value:__ `\"zero\"`\n   */\n  offset?: 'zero' | 'center' | 'normalize';\n  /**\n   * Field that determines the order of leaves in the stacked charts.\n   */\n  sort?: SortField[];\n  /**\n   * Output field names. This can be either a string or an array of strings with two elements denoting the name for the fields for stack start and stack end respectively.\n   * If a single string(e.g., `\"val\"`) is provided, the end field will be `\"val_end\"`.\n   */\n  as: FieldName | [FieldName, FieldName];\n}\n\nexport type WindowOnlyOp =\n  | 'row_number'\n  | 'rank'\n  | 'dense_rank'\n  | 'percent_rank'\n  | 'cume_dist'\n  | 'ntile'\n  | 'lag'\n  | 'lead'\n  | 'first_value'\n  | 'last_value'\n  | 'nth_value';\n\nexport interface WindowFieldDef {\n  /**\n   * The window or aggregation operation to apply within a window (e.g., `\"rank\"`, `\"lead\"`, `\"sum\"`, `\"average\"` or `\"count\"`). See the list of all supported operations [here](https://vega.github.io/vega-lite/docs/window.html#ops).\n   */\n  op: AggregateOp | WindowOnlyOp;\n\n  /**\n   * Parameter values for the window functions. Parameter values can be omitted for operations that do not accept a parameter.\n   *\n   * See the list of all supported operations and their parameters [here](https://vega.github.io/vega-lite/docs/transforms/window.html).\n   */\n  param?: number;\n\n  /**\n   * The data field for which to compute the aggregate or window function. This can be omitted for window functions that do not operate over a field such as `\"count\"`, `\"rank\"`, `\"dense_rank\"`.\n   */\n  field?: FieldName;\n\n  /**\n   * The output name for the window operation.\n   */\n  as: FieldName;\n}\n\nexport interface WindowTransform {\n  /**\n   * The definition of the fields in the window, and what calculations to use.\n   */\n  window: WindowFieldDef[];\n\n  /**\n   * A frame specification as a two-element array indicating how the sliding window should proceed. The array entries should either be a number indicating the offset from the current data object, or null to indicate unbounded rows preceding or following the current data object. The default value is `[null, 0]`, indicating that the sliding window includes the current object and all preceding objects. The value `[-5, 5]` indicates that the window should include five objects preceding and five objects following the current object. Finally, `[null, null]` indicates that the window frame should always include all data objects. If you this frame and want to assign the same value to add objects, you can use the simpler [join aggregate transform](https://vega.github.io/vega-lite/docs/joinaggregate.html). The only operators affected are the aggregation operations and the `first_value`, `last_value`, and `nth_value` window operations. The other window operations are not affected by this.\n   *\n   * __Default value:__:  `[null, 0]` (includes the current object and all preceding objects)\n   */\n  frame?: (null | number)[];\n\n  /**\n   * Indicates if the sliding window frame should ignore peer values (data that are considered identical by the sort criteria). The default is false, causing the window frame to expand to include all peer values. If set to true, the window frame will be defined by offset values only. This setting only affects those operations that depend on the window frame, namely aggregation operations and the first_value, last_value, and nth_value window operations.\n   *\n   * __Default value:__ `false`\n   */\n  ignorePeers?: boolean;\n\n  /**\n   * The data fields for partitioning the data objects into separate windows. If unspecified, all data points will be in a single window.\n   */\n  groupby?: FieldName[];\n\n  /**\n   * A sort field definition for sorting data objects within a window. If two data objects are considered equal by the comparator, they are considered \"peer\" values of equal rank. If sort is not specified, the order is undefined: data objects are processed in the order they are observed and none are considered peers (the ignorePeers parameter is ignored and treated as if set to `true`).\n   */\n  sort?: SortField[];\n}\n\nexport interface JoinAggregateFieldDef {\n  /**\n   * The aggregation operation to apply (e.g., `\"sum\"`, `\"average\"` or `\"count\"`). See the list of all supported operations [here](https://vega.github.io/vega-lite/docs/aggregate.html#ops).\n   */\n  op: AggregateOp;\n\n  /**\n   * The data field for which to compute the aggregate function. This can be omitted for functions that do not operate over a field such as `\"count\"`.\n   */\n  field?: FieldName;\n\n  /**\n   * The output name for the join aggregate operation.\n   */\n  as: FieldName;\n}\n\nexport interface JoinAggregateTransform {\n  /**\n   * The definition of the fields in the join aggregate, and what calculations to use.\n   */\n  joinaggregate: JoinAggregateFieldDef[];\n\n  /**\n   * The data fields for partitioning the data objects into separate groups. If unspecified, all data points will be in a single group.\n   */\n  groupby?: FieldName[];\n}\n\nexport interface ImputeSequence {\n  /**\n   * The starting value of the sequence.\n   * __Default value:__ `0`\n   */\n  start?: number;\n  /**\n   * The ending value(exclusive) of the sequence.\n   */\n  stop: number;\n  /**\n   * The step value between sequence entries.\n   * __Default value:__ `1` or `-1` if `stop < start`\n   */\n  step?: number;\n}\n\nexport function isImputeSequence(t: ImputeSequence | any[] | undefined): t is ImputeSequence {\n  return hasProperty(t, 'stop');\n}\n\nexport interface ImputeTransform extends ImputeParams {\n  /**\n   * The data field for which the missing values should be imputed.\n   */\n  impute: FieldName;\n\n  /**\n   * A key field that uniquely identifies data objects within a group.\n   * Missing key values (those occurring in the data but not in the current group) will be imputed.\n   */\n  key: FieldName;\n\n  /**\n   * An optional array of fields by which to group the values.\n   * Imputation will then be performed on a per-group basis.\n   */\n  groupby?: FieldName[];\n}\n\nexport interface FlattenTransform {\n  /**\n   * An array of one or more data fields containing arrays to flatten.\n   * If multiple fields are specified, their array values should have a parallel structure, ideally with the same length.\n   * If the lengths of parallel arrays do not match,\n   * the longest array will be used with `null` values added for missing entries.\n   */\n  flatten: FieldName[];\n\n  /**\n   * The output field names for extracted array values.\n   *\n   * __Default value:__ The field name of the corresponding array field\n   */\n  as?: FieldName[];\n}\n\nexport interface SampleTransform {\n  /**\n   * The maximum number of data objects to include in the sample.\n   *\n   * __Default value:__ `1000`\n   */\n  sample: number;\n}\n\nexport interface LookupBase {\n  /**\n   * Key in data to lookup.\n   */\n  key: FieldName;\n  /**\n   * Fields in foreign data or selection to lookup.\n   * If not specified, the entire object is queried.\n   */\n  fields?: FieldName[];\n}\n\nexport interface LookupData extends LookupBase {\n  /**\n   * Secondary data source to lookup in.\n   */\n  data: Data;\n}\n\nexport interface LookupSelection extends LookupBase {\n  /**\n   * Selection parameter name to look up.\n   */\n  param: ParameterName;\n}\n\nexport interface LookupTransform {\n  /**\n   * Key in primary data source.\n   */\n  lookup: string;\n\n  /**\n   * The output fields on which to store the looked up data values.\n   *\n   * For data lookups, this property may be left blank if `from.fields`\n   * has been specified (those field names will be used); if `from.fields`\n   * has not been specified, `as` must be a string.\n   *\n   * For selection lookups, this property is optional: if unspecified,\n   * looked up values will be stored under a property named for the selection;\n   * and if specified, it must correspond to `from.fields`.\n   */\n  as?: FieldName | FieldName[];\n\n  /**\n   * The default value to use if lookup fails.\n   *\n   * __Default value:__ `null`\n   */\n  default?: any;\n\n  /**\n   * Data source or selection for secondary data reference.\n   */\n  from: LookupData | LookupSelection;\n}\n\nexport function isLookup(t: Transform): t is LookupTransform {\n  return hasProperty(t, 'lookup');\n}\n\nexport function isLookupData(from: LookupData | LookupSelection): from is LookupData {\n  return hasProperty(from, 'data');\n}\n\nexport function isLookupSelection(from: LookupData | LookupSelection): from is LookupSelection {\n  return hasProperty(from, 'param');\n}\n\nexport interface FoldTransform {\n  /**\n   * An array of data fields indicating the properties to fold.\n   */\n  fold: FieldName[];\n\n  /**\n   * The output field names for the key and value properties produced by the fold transform.\n   * __Default value:__ `[\"key\", \"value\"]`\n   */\n  as?: [FieldName, FieldName];\n}\n\nexport interface ExtentTransform {\n  /**\n   * The field of which to get the extent.\n   */\n  extent: FieldName;\n\n  /**\n   * The output parameter produced by the extent transform.\n   */\n  param: ParameterName;\n}\n\nexport interface PivotTransform {\n  /**\n   * The data field to pivot on. The unique values of this field become new field names in the output stream.\n   */\n  pivot: FieldName;\n\n  /**\n   * The data field to populate pivoted fields. The aggregate values of this field become the values of the new pivoted fields.\n   */\n  value: FieldName;\n\n  /**\n   * The optional data fields to group by. If not specified, a single group containing all data objects will be used.\n   */\n  groupby?: FieldName[];\n\n  /**\n   * An optional parameter indicating the maximum number of pivoted fields to generate.\n   * The default (`0`) applies no limit. The pivoted `pivot` names are sorted in ascending order prior to enforcing the limit.\n   * __Default value:__ `0`\n   */\n  limit?: number;\n\n  /**\n   * The aggregation operation to apply to grouped `value` field values.\n   * __Default value:__ `sum`\n   */\n  op?: AggregateOp;\n}\n\nexport function isPivot(t: Transform): t is PivotTransform {\n  return hasProperty(t, 'pivot');\n}\n\nexport interface DensityTransform {\n  /**\n   * The data field for which to perform density estimation.\n   */\n  density: FieldName;\n\n  /**\n   * The data fields to group by. If not specified, a single group containing all data objects will be used.\n   */\n  groupby?: FieldName[];\n\n  /**\n   * A boolean flag indicating whether to produce density estimates (false) or cumulative density estimates (true).\n   *\n   * __Default value:__ `false`\n   */\n  cumulative?: boolean;\n\n  /**\n   * A boolean flag indicating if the output values should be probability estimates (false) or smoothed counts (true).\n   *\n   * __Default value:__ `false`\n   */\n  counts?: boolean;\n\n  /**\n   * The bandwidth (standard deviation) of the Gaussian kernel. If unspecified or set to zero, the bandwidth value is automatically estimated from the input data using Scott’s rule.\n   */\n  bandwidth?: number;\n\n  /**\n   * A [min, max] domain from which to sample the distribution. If unspecified, the extent will be determined by the observed minimum and maximum values of the density value field.\n   */\n  extent?: [number, number];\n\n  /**\n   * The minimum number of samples to take along the extent domain for plotting the density.\n   *\n   * __Default value:__ `25`\n   */\n  minsteps?: number;\n\n  /**\n   * The maximum number of samples to take along the extent domain for plotting the density.\n   *\n   * __Default value:__ `200`\n   */\n  maxsteps?: number;\n\n  /**\n   * The exact number of samples to take along the extent domain for plotting the density. If specified, overrides both minsteps and maxsteps to set an exact number of uniform samples. Potentially useful in conjunction with a fixed extent to ensure consistent sample points for stacked densities.\n   */\n  steps?: number;\n\n  /**\n   * The output fields for the sample value and corresponding density estimate.\n   *\n   * __Default value:__ `[\"value\", \"density\"]`\n   */\n  as?: [FieldName, FieldName];\n  /**\n   * Indicates how parameters for multiple densities should be resolved.\n   * If `\"independent\"`, each density may have its own domain extent and dynamic number of curve sample steps.\n   * If `\"shared\"`, the KDE transform will ensure that all densities are defined over a shared domain and curve steps, enabling stacking.\n   *\n   * __Default value:__ `\"shared\"`\n   */\n  resolve?: 'independent' | 'shared';\n}\n\nexport function isDensity(t: Transform): t is DensityTransform {\n  return hasProperty(t, 'density');\n}\n\nexport interface QuantileTransform {\n  /**\n   * The data field for which to perform quantile estimation.\n   */\n  quantile: FieldName;\n\n  /**\n   * The data fields to group by. If not specified, a single group containing all data objects will be used.\n   */\n  groupby?: FieldName[];\n\n  /**\n   * An array of probabilities in the range (0, 1) for which to compute quantile values. If not specified, the *step* parameter will be used.\n   */\n  probs?: number[];\n\n  /**\n   * A probability step size (default 0.01) for sampling quantile values. All values from one-half the step size up to 1 (exclusive) will be sampled. This parameter is only used if the *probs* parameter is not provided.\n   */\n  step?: number;\n\n  /**\n   * The output field names for the probability and quantile values.\n   *\n   * __Default value:__ `[\"prob\", \"value\"]`\n   */\n  as?: [FieldName, FieldName];\n}\n\nexport function isQuantile(t: Transform): t is QuantileTransform {\n  return hasProperty(t, 'quantile');\n}\n\nexport interface RegressionTransform {\n  /**\n   * The data field of the dependent variable to predict.\n   */\n  regression: FieldName;\n\n  /**\n   * The data field of the independent variable to use a predictor.\n   */\n  on: FieldName;\n\n  /**\n   * The data fields to group by. If not specified, a single group containing all data objects will be used.\n   */\n  groupby?: FieldName[];\n\n  /**\n   * The functional form of the regression model. One of `\"linear\"`, `\"log\"`, `\"exp\"`, `\"pow\"`, `\"quad\"`, or `\"poly\"`.\n   *\n   * __Default value:__ `\"linear\"`\n   */\n  method?: 'linear' | 'log' | 'exp' | 'pow' | 'quad' | 'poly';\n\n  /**\n   * The polynomial order (number of coefficients) for the 'poly' method.\n   *\n   * __Default value:__ `3`\n   */\n  order?: number;\n\n  /**\n   * A [min, max] domain over the independent (x) field for the starting and ending points of the generated trend line.\n   */\n  extent?: [number, number];\n\n  /**\n   * A boolean flag indicating if the transform should return the regression model parameters (one object per group), rather than trend line points.\n   * The resulting objects include a `coef` array of fitted coefficient values (starting with the intercept term and then including terms of increasing order)\n   * and an `rSquared` value (indicating the total variance explained by the model).\n   *\n   * __Default value:__ `false`\n   */\n  params?: boolean;\n\n  /**\n   * The output field names for the smoothed points generated by the regression transform.\n   *\n   * __Default value:__ The field names of the input x and y values.\n   */\n  as?: [FieldName, FieldName];\n}\n\nexport function isRegression(t: Transform): t is RegressionTransform {\n  return hasProperty(t, 'regression');\n}\n\nexport interface LoessTransform {\n  /**\n   * The data field of the dependent variable to smooth.\n   */\n  loess: FieldName;\n\n  /**\n   * The data field of the independent variable to use a predictor.\n   */\n  on: FieldName;\n\n  /**\n   * The data fields to group by. If not specified, a single group containing all data objects will be used.\n   */\n  groupby?: FieldName[];\n\n  /**\n   * A bandwidth parameter in the range `[0, 1]` that determines the amount of smoothing.\n   *\n   * __Default value:__ `0.3`\n   */\n  bandwidth?: number;\n\n  /**\n   * The output field names for the smoothed points generated by the loess transform.\n   *\n   * __Default value:__ The field names of the input x and y values.\n   */\n  as?: [FieldName, FieldName];\n}\n\nexport function isLoess(t: Transform): t is LoessTransform {\n  return hasProperty(t, 'loess');\n}\n\nexport function isSample(t: Transform): t is SampleTransform {\n  return hasProperty(t, 'sample');\n}\n\nexport function isWindow(t: Transform): t is WindowTransform {\n  return hasProperty(t, 'window');\n}\n\nexport function isJoinAggregate(t: Transform): t is JoinAggregateTransform {\n  return hasProperty(t, 'joinaggregate');\n}\n\nexport function isFlatten(t: Transform): t is FlattenTransform {\n  return hasProperty(t, 'flatten');\n}\nexport function isCalculate(t: Transform): t is CalculateTransform {\n  return hasProperty(t, 'calculate');\n}\n\nexport function isBin(t: Transform): t is BinTransform {\n  return hasProperty(t, 'bin');\n}\n\nexport function isImpute(t: Transform): t is ImputeTransform {\n  return hasProperty(t, 'impute');\n}\n\nexport function isTimeUnit(t: Transform): t is TimeUnitTransform {\n  return hasProperty(t, 'timeUnit');\n}\n\nexport function isAggregate(t: Transform): t is AggregateTransform {\n  return hasProperty(t, 'aggregate');\n}\n\nexport function isStack(t: Transform): t is StackTransform {\n  return hasProperty(t, 'stack');\n}\n\nexport function isFold(t: Transform): t is FoldTransform {\n  return hasProperty(t, 'fold');\n}\n\nexport function isExtent(t: Transform): t is ExtentTransform {\n  return hasProperty(t, 'extent') && !hasProperty(t, 'density') && !hasProperty(t, 'regression');\n}\nexport type Transform =\n  | AggregateTransform\n  | BinTransform\n  | CalculateTransform\n  | DensityTransform\n  | ExtentTransform\n  | FilterTransform\n  | FlattenTransform\n  | FoldTransform\n  | ImputeTransform\n  | JoinAggregateTransform\n  | LoessTransform\n  | LookupTransform\n  | QuantileTransform\n  | RegressionTransform\n  | TimeUnitTransform\n  | SampleTransform\n  | StackTransform\n  | WindowTransform\n  | PivotTransform;\n\nexport function normalizeTransform(transform: Transform[]) {\n  return transform.map(t => {\n    if (isFilter(t)) {\n      return {\n        filter: normalizeLogicalComposition(t.filter, normalizePredicate)\n      };\n    }\n    return t;\n  });\n}\n"],"mappings":"AAKA,SAA4BA,2BAA2B,QAAO,WAAW;AAEzE,SAAQC,kBAAkB,QAAkB,aAAa;AAGzD,SAAQC,WAAW,QAAO,QAAQ;AA2BlC,OAAM,SAAUC,QAAQA,CAACC,CAAY;EACnC,OAAOF,WAAW,CAACE,CAAC,EAAE,QAAQ,CAAC;AACjC;AA8NA,OAAM,SAAUC,gBAAgBA,CAACD,CAAqC;EACpE,OAAOF,WAAW,CAACE,CAAC,EAAE,MAAM,CAAC;AAC/B;AAyGA,OAAM,SAAUE,QAAQA,CAACF,CAAY;EACnC,OAAOF,WAAW,CAACE,CAAC,EAAE,QAAQ,CAAC;AACjC;AAEA,OAAM,SAAUG,YAAYA,CAACC,IAAkC;EAC7D,OAAON,WAAW,CAACM,IAAI,EAAE,MAAM,CAAC;AAClC;AAEA,OAAM,SAAUC,iBAAiBA,CAACD,IAAkC;EAClE,OAAON,WAAW,CAACM,IAAI,EAAE,OAAO,CAAC;AACnC;AAyDA,OAAM,SAAUE,OAAOA,CAACN,CAAY;EAClC,OAAOF,WAAW,CAACE,CAAC,EAAE,OAAO,CAAC;AAChC;AAwEA,OAAM,SAAUO,SAASA,CAACP,CAAY;EACpC,OAAOF,WAAW,CAACE,CAAC,EAAE,SAAS,CAAC;AAClC;AA+BA,OAAM,SAAUQ,UAAUA,CAACR,CAAY;EACrC,OAAOF,WAAW,CAACE,CAAC,EAAE,UAAU,CAAC;AACnC;AAsDA,OAAM,SAAUS,YAAYA,CAACT,CAAY;EACvC,OAAOF,WAAW,CAACE,CAAC,EAAE,YAAY,CAAC;AACrC;AAiCA,OAAM,SAAUU,OAAOA,CAACV,CAAY;EAClC,OAAOF,WAAW,CAACE,CAAC,EAAE,OAAO,CAAC;AAChC;AAEA,OAAM,SAAUW,QAAQA,CAACX,CAAY;EACnC,OAAOF,WAAW,CAACE,CAAC,EAAE,QAAQ,CAAC;AACjC;AAEA,OAAM,SAAUY,QAAQA,CAACZ,CAAY;EACnC,OAAOF,WAAW,CAACE,CAAC,EAAE,QAAQ,CAAC;AACjC;AAEA,OAAM,SAAUa,eAAeA,CAACb,CAAY;EAC1C,OAAOF,WAAW,CAACE,CAAC,EAAE,eAAe,CAAC;AACxC;AAEA,OAAM,SAAUc,SAASA,CAACd,CAAY;EACpC,OAAOF,WAAW,CAACE,CAAC,EAAE,SAAS,CAAC;AAClC;AACA,OAAM,SAAUe,WAAWA,CAACf,CAAY;EACtC,OAAOF,WAAW,CAACE,CAAC,EAAE,WAAW,CAAC;AACpC;AAEA,OAAM,SAAUgB,KAAKA,CAAChB,CAAY;EAChC,OAAOF,WAAW,CAACE,CAAC,EAAE,KAAK,CAAC;AAC9B;AAEA,OAAM,SAAUiB,QAAQA,CAACjB,CAAY;EACnC,OAAOF,WAAW,CAACE,CAAC,EAAE,QAAQ,CAAC;AACjC;AAEA,OAAM,SAAUkB,UAAUA,CAAClB,CAAY;EACrC,OAAOF,WAAW,CAACE,CAAC,EAAE,UAAU,CAAC;AACnC;AAEA,OAAM,SAAUmB,WAAWA,CAACnB,CAAY;EACtC,OAAOF,WAAW,CAACE,CAAC,EAAE,WAAW,CAAC;AACpC;AAEA,OAAM,SAAUoB,OAAOA,CAACpB,CAAY;EAClC,OAAOF,WAAW,CAACE,CAAC,EAAE,OAAO,CAAC;AAChC;AAEA,OAAM,SAAUqB,MAAMA,CAACrB,CAAY;EACjC,OAAOF,WAAW,CAACE,CAAC,EAAE,MAAM,CAAC;AAC/B;AAEA,OAAM,SAAUsB,QAAQA,CAACtB,CAAY;EACnC,OAAOF,WAAW,CAACE,CAAC,EAAE,QAAQ,CAAC,IAAI,CAACF,WAAW,CAACE,CAAC,EAAE,SAAS,CAAC,IAAI,CAACF,WAAW,CAACE,CAAC,EAAE,YAAY,CAAC;AAChG;AAsBA,OAAM,SAAUuB,kBAAkBA,CAACC,SAAsB;EACvD,OAAOA,SAAS,CAACC,GAAG,CAACzB,CAAC,IAAG;IACvB,IAAID,QAAQ,CAACC,CAAC,CAAC,EAAE;MACf,OAAO;QACL0B,MAAM,EAAE9B,2BAA2B,CAACI,CAAC,CAAC0B,MAAM,EAAE7B,kBAAkB;OACjE;IACH;IACA,OAAOG,CAAC;EACV,CAAC,CAAC;AACJ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}