{"ast":null,"code":"import { AncestorParse } from '.';\nimport { isGenerator, isGraticuleGenerator, isInlineData, isNamedData, isSequenceGenerator, isUrlData, DataSourceType } from '../../data';\nimport { getDataSourcesForHandlingInvalidValues } from '../invalid/datasources';\nimport * as log from '../../log';\nimport { isPathMark } from '../../mark';\nimport { isAggregate, isBin, isCalculate, isDensity, isExtent, isFilter, isFlatten, isFold, isImpute, isJoinAggregate, isLoess, isLookup, isPivot, isQuantile, isRegression, isSample, isStack, isTimeUnit, isWindow } from '../../transform';\nimport { deepEqual, mergeDeep } from '../../util';\nimport { getMarkPropOrConfig } from '../common';\nimport { isFacetModel, isLayerModel, isUnitModel } from '../model';\nimport { requiresSelectionId } from '../selection';\nimport { materializeSelections } from '../selection/parse';\nimport { AggregateNode } from './aggregate';\nimport { BinNode } from './bin';\nimport { CalculateNode } from './calculate';\nimport { OutputNode } from './dataflow';\nimport { DensityTransformNode } from './density';\nimport { ExtentTransformNode } from './extent';\nimport { FacetNode } from './facet';\nimport { FilterNode } from './filter';\nimport { FilterInvalidNode } from './filterinvalid';\nimport { FlattenTransformNode } from './flatten';\nimport { FoldTransformNode } from './fold';\nimport { getImplicitFromEncoding, getImplicitFromFilterTransform, getImplicitFromSelection, ParseNode } from './formatparse';\nimport { GeoJSONNode } from './geojson';\nimport { GeoPointNode } from './geopoint';\nimport { GraticuleNode } from './graticule';\nimport { IdentifierNode } from './identifier';\nimport { ImputeNode } from './impute';\nimport { JoinAggregateTransformNode } from './joinaggregate';\nimport { makeJoinAggregateFromFacet } from './joinaggregatefacet';\nimport { LoessTransformNode } from './loess';\nimport { LookupNode } from './lookup';\nimport { PivotTransformNode } from './pivot';\nimport { QuantileTransformNode } from './quantile';\nimport { RegressionTransformNode } from './regression';\nimport { SampleTransformNode } from './sample';\nimport { SequenceNode } from './sequence';\nimport { SourceNode } from './source';\nimport { StackNode } from './stack';\nimport { TimeUnitNode } from './timeunit';\nimport { WindowTransformNode } from './window';\nexport function findSource(data, sources) {\n  for (const other of sources) {\n    const otherData = other.data;\n    // if both datasets have a name defined, we cannot merge\n    if (data.name && other.hasName() && data.name !== other.dataName) {\n      continue;\n    }\n    const formatMesh = data.format?.mesh;\n    const otherFeature = otherData.format?.feature;\n    // feature and mesh are mutually exclusive\n    if (formatMesh && otherFeature) {\n      continue;\n    }\n    // we have to extract the same feature or mesh\n    const formatFeature = data.format?.feature;\n    if ((formatFeature || otherFeature) && formatFeature !== otherFeature) {\n      continue;\n    }\n    const otherMesh = otherData.format?.mesh;\n    if ((formatMesh || otherMesh) && formatMesh !== otherMesh) {\n      continue;\n    }\n    if (isInlineData(data) && isInlineData(otherData)) {\n      if (deepEqual(data.values, otherData.values)) {\n        return other;\n      }\n    } else if (isUrlData(data) && isUrlData(otherData)) {\n      if (data.url === otherData.url) {\n        return other;\n      }\n    } else if (isNamedData(data)) {\n      if (data.name === other.dataName) {\n        return other;\n      }\n    }\n  }\n  return null;\n}\nfunction parseRoot(model, sources) {\n  if (model.data || !model.parent) {\n    // if the model defines a data source or is the root, create a source node\n    if (model.data === null) {\n      // data: null means we should ignore the parent's data so we just create a new data source\n      const source = new SourceNode({\n        values: []\n      });\n      sources.push(source);\n      return source;\n    }\n    const existingSource = findSource(model.data, sources);\n    if (existingSource) {\n      if (!isGenerator(model.data)) {\n        existingSource.data.format = mergeDeep({}, model.data.format, existingSource.data.format);\n      }\n      // if the new source has a name but the existing one does not, we can set it\n      if (!existingSource.hasName() && model.data.name) {\n        existingSource.dataName = model.data.name;\n      }\n      return existingSource;\n    } else {\n      const source = new SourceNode(model.data);\n      sources.push(source);\n      return source;\n    }\n  } else {\n    // If we don't have a source defined (overriding parent's data), use the parent's facet root or main.\n    return model.parent.component.data.facetRoot ? model.parent.component.data.facetRoot : model.parent.component.data.main;\n  }\n}\n/**\n * Parses a transform array into a chain of connected dataflow nodes.\n */\nexport function parseTransformArray(head, model, ancestorParse) {\n  let lookupCounter = 0;\n  for (const t of model.transforms) {\n    let derivedType = undefined;\n    let transformNode;\n    if (isCalculate(t)) {\n      transformNode = head = new CalculateNode(head, t);\n      derivedType = 'derived';\n    } else if (isFilter(t)) {\n      const implicit = getImplicitFromFilterTransform(t);\n      transformNode = head = ParseNode.makeWithAncestors(head, {}, implicit, ancestorParse) ?? head;\n      head = new FilterNode(head, model, t.filter);\n    } else if (isBin(t)) {\n      transformNode = head = BinNode.makeFromTransform(head, t, model);\n      derivedType = 'number';\n    } else if (isTimeUnit(t)) {\n      derivedType = 'date';\n      const parsedAs = ancestorParse.getWithExplicit(t.field);\n      // Create parse node because the input to time unit is always date.\n      if (parsedAs.value === undefined) {\n        head = new ParseNode(head, {\n          [t.field]: derivedType\n        });\n        ancestorParse.set(t.field, derivedType, false);\n      }\n      transformNode = head = TimeUnitNode.makeFromTransform(head, t);\n    } else if (isAggregate(t)) {\n      transformNode = head = AggregateNode.makeFromTransform(head, t);\n      derivedType = 'number';\n      if (requiresSelectionId(model)) {\n        head = new IdentifierNode(head);\n      }\n    } else if (isLookup(t)) {\n      transformNode = head = LookupNode.make(head, model, t, lookupCounter++);\n      derivedType = 'derived';\n    } else if (isWindow(t)) {\n      transformNode = head = new WindowTransformNode(head, t);\n      derivedType = 'number';\n    } else if (isJoinAggregate(t)) {\n      transformNode = head = new JoinAggregateTransformNode(head, t);\n      derivedType = 'number';\n    } else if (isStack(t)) {\n      transformNode = head = StackNode.makeFromTransform(head, t);\n      derivedType = 'derived';\n    } else if (isFold(t)) {\n      transformNode = head = new FoldTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isExtent(t)) {\n      transformNode = head = new ExtentTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isFlatten(t)) {\n      transformNode = head = new FlattenTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isPivot(t)) {\n      transformNode = head = new PivotTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isSample(t)) {\n      head = new SampleTransformNode(head, t);\n    } else if (isImpute(t)) {\n      transformNode = head = ImputeNode.makeFromTransform(head, t);\n      derivedType = 'derived';\n    } else if (isDensity(t)) {\n      transformNode = head = new DensityTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isQuantile(t)) {\n      transformNode = head = new QuantileTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isRegression(t)) {\n      transformNode = head = new RegressionTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isLoess(t)) {\n      transformNode = head = new LoessTransformNode(head, t);\n      derivedType = 'derived';\n    } else {\n      log.warn(log.message.invalidTransformIgnored(t));\n      continue;\n    }\n    if (transformNode && derivedType !== undefined) {\n      for (const field of transformNode.producedFields() ?? []) {\n        ancestorParse.set(field, derivedType, false);\n      }\n    }\n  }\n  return head;\n}\n/*\nDescription of the dataflow (http://asciiflow.com/):\n     +--------+\n     | Source |\n     +---+----+\n         |\n         v\n     FormatParse\n     (explicit)\n         |\n         v\n     Transforms\n(Filter, Calculate, Binning, TimeUnit, Aggregate, Window, ...)\n         |\n         v\n     FormatParse\n     (implicit)\n         |\n         v\n Binning (in `encoding`)\n         |\n         v\n Timeunit (in `encoding`)\n         |\n         v\nFormula From Sort Array\n         |\n         v\n      +--+--+\n      | Raw |\n      +-----+\n         |\n         v\n  Aggregate (in `encoding`)\n         |\n         v\n  Stack (in `encoding`)\n         |\n         v\n+- - - - - - - - - - -+\n|   PreFilterInvalid  | - - - -> scale domains\n|(when scales need it)|\n+- - - - - - - - - - -+\n         |\n         v\n  Invalid Filter (if the main data source needs it)\n         |\n         v\n   +----------+\n   |   Main   | - - - -> scale domains\n   +----------+\n         |\n         v\n+- - - - - - - - - - -+\n|   PostFilterInvalid | - - - -> scale domains\n|(when scales need it)|\n+- - - - - - - - - - -+\n         |\n         v\n     +-------+\n     | Facet |----> \"column\", \"column-layout\", and \"row\"\n     +-------+\n         |\n         v\n  ...Child data...\n*/\nexport function parseData(model) {\n  let head = parseRoot(model, model.component.data.sources);\n  const {\n    outputNodes,\n    outputNodeRefCounts\n  } = model.component.data;\n  const data = model.data;\n  const newData = data && (isGenerator(data) || isUrlData(data) || isInlineData(data));\n  const ancestorParse = !newData && model.parent ? model.parent.component.data.ancestorParse.clone() : new AncestorParse();\n  if (isGenerator(data)) {\n    // insert generator transform\n    if (isSequenceGenerator(data)) {\n      head = new SequenceNode(head, data.sequence);\n    } else if (isGraticuleGenerator(data)) {\n      head = new GraticuleNode(head, data.graticule);\n    }\n    // no parsing necessary for generator\n    ancestorParse.parseNothing = true;\n  } else if (data?.format?.parse === null) {\n    // format.parse: null means disable parsing\n    ancestorParse.parseNothing = true;\n  }\n  head = ParseNode.makeExplicit(head, model, ancestorParse) ?? head;\n  // Default discrete selections require an identifer transform to\n  // uniquely identify data points. Add this transform at the head of\n  // the pipeline such that the identifier field is available for all\n  // subsequent datasets. During optimization, we will remove this\n  // transform if it proves to be unnecessary. Additional identifier\n  // transforms will be necessary when new tuples are constructed\n  // (e.g., post-aggregation).\n  head = new IdentifierNode(head);\n  // HACK: This is equivalent for merging bin extent for union scale.\n  // FIXME(https://github.com/vega/vega-lite/issues/2270): Correctly merge extent / bin node for shared bin scale\n  const parentIsLayer = model.parent && isLayerModel(model.parent);\n  if (isUnitModel(model) || isFacetModel(model)) {\n    if (parentIsLayer) {\n      head = BinNode.makeFromEncoding(head, model) ?? head;\n    }\n  }\n  if (model.transforms.length > 0) {\n    head = parseTransformArray(head, model, ancestorParse);\n  }\n  // create parse nodes for fields that need to be parsed (or flattened) implicitly\n  const implicitSelection = getImplicitFromSelection(model);\n  const implicitEncoding = getImplicitFromEncoding(model);\n  head = ParseNode.makeWithAncestors(head, {}, {\n    ...implicitSelection,\n    ...implicitEncoding\n  }, ancestorParse) ?? head;\n  if (isUnitModel(model)) {\n    head = GeoJSONNode.parseAll(head, model);\n    head = GeoPointNode.parseAll(head, model);\n  }\n  if (isUnitModel(model) || isFacetModel(model)) {\n    if (!parentIsLayer) {\n      head = BinNode.makeFromEncoding(head, model) ?? head;\n    }\n    head = TimeUnitNode.makeFromEncoding(head, model) ?? head;\n    head = CalculateNode.parseAllForSortIndex(head, model);\n  }\n  // add an output node pre aggregation\n  const raw = head = makeOutputNode(DataSourceType.Raw, model, head);\n  if (isUnitModel(model)) {\n    const agg = AggregateNode.makeFromEncoding(head, model);\n    if (agg) {\n      head = agg;\n      if (requiresSelectionId(model)) {\n        head = new IdentifierNode(head);\n      }\n    }\n    head = ImputeNode.makeFromEncoding(head, model) ?? head;\n    head = StackNode.makeFromEncoding(head, model) ?? head;\n  }\n  let preFilterInvalid;\n  let dataSourcesForHandlingInvalidValues;\n  if (isUnitModel(model)) {\n    const {\n      markDef,\n      mark,\n      config\n    } = model;\n    const invalid = getMarkPropOrConfig('invalid', markDef, config);\n    const {\n      marks,\n      scales\n    } = dataSourcesForHandlingInvalidValues = getDataSourcesForHandlingInvalidValues({\n      invalid,\n      isPath: isPathMark(mark)\n    });\n    if (marks !== scales && scales === 'include-invalid-values') {\n      // Create a seperate preFilterInvalid dataSource if scales need pre-filter data but marks needs post-filter.\n      preFilterInvalid = head = makeOutputNode(DataSourceType.PreFilterInvalid, model, head);\n    }\n    if (marks === 'exclude-invalid-values') {\n      head = FilterInvalidNode.make(head, model, dataSourcesForHandlingInvalidValues) ?? head;\n    }\n  }\n  // output \"main\" node for marks\n  const main = head = makeOutputNode(DataSourceType.Main, model, head);\n  let postFilterInvalid;\n  if (isUnitModel(model) && dataSourcesForHandlingInvalidValues) {\n    const {\n      marks,\n      scales\n    } = dataSourcesForHandlingInvalidValues;\n    if (marks === 'include-invalid-values' && scales === 'exclude-invalid-values') {\n      // Create a seperate postFilterInvalid dataSource if scales need post-filter data but marks needs pre-filter.\n      head = FilterInvalidNode.make(head, model, dataSourcesForHandlingInvalidValues) ?? head;\n      postFilterInvalid = head = makeOutputNode(DataSourceType.PostFilterInvalid, model, head);\n    }\n  }\n  if (isUnitModel(model)) {\n    materializeSelections(model, main);\n  }\n  // add facet marker\n  let facetRoot = null;\n  if (isFacetModel(model)) {\n    const facetName = model.getName('facet');\n    // Derive new aggregate for facet's sort field\n    // augment data source with new fields for crossed facet\n    head = makeJoinAggregateFromFacet(head, model.facet) ?? head;\n    facetRoot = new FacetNode(head, model, facetName, main.getSource());\n    outputNodes[facetName] = facetRoot;\n  }\n  return {\n    ...model.component.data,\n    outputNodes,\n    outputNodeRefCounts,\n    raw,\n    main,\n    facetRoot,\n    ancestorParse,\n    preFilterInvalid,\n    postFilterInvalid\n  };\n}\nfunction makeOutputNode(dataSourceType, model, head) {\n  const {\n    outputNodes,\n    outputNodeRefCounts\n  } = model.component.data;\n  const name = model.getDataName(dataSourceType);\n  const node = new OutputNode(head, name, dataSourceType, outputNodeRefCounts);\n  outputNodes[name] = node;\n  return node;\n}","map":{"version":3,"names":["AncestorParse","isGenerator","isGraticuleGenerator","isInlineData","isNamedData","isSequenceGenerator","isUrlData","DataSourceType","getDataSourcesForHandlingInvalidValues","log","isPathMark","isAggregate","isBin","isCalculate","isDensity","isExtent","isFilter","isFlatten","isFold","isImpute","isJoinAggregate","isLoess","isLookup","isPivot","isQuantile","isRegression","isSample","isStack","isTimeUnit","isWindow","deepEqual","mergeDeep","getMarkPropOrConfig","isFacetModel","isLayerModel","isUnitModel","requiresSelectionId","materializeSelections","AggregateNode","BinNode","CalculateNode","OutputNode","DensityTransformNode","ExtentTransformNode","FacetNode","FilterNode","FilterInvalidNode","FlattenTransformNode","FoldTransformNode","getImplicitFromEncoding","getImplicitFromFilterTransform","getImplicitFromSelection","ParseNode","GeoJSONNode","GeoPointNode","GraticuleNode","IdentifierNode","ImputeNode","JoinAggregateTransformNode","makeJoinAggregateFromFacet","LoessTransformNode","LookupNode","PivotTransformNode","QuantileTransformNode","RegressionTransformNode","SampleTransformNode","SequenceNode","SourceNode","StackNode","TimeUnitNode","WindowTransformNode","findSource","data","sources","other","otherData","name","hasName","dataName","formatMesh","format","mesh","otherFeature","feature","formatFeature","otherMesh","values","url","parseRoot","model","parent","source","push","existingSource","component","facetRoot","main","parseTransformArray","head","ancestorParse","lookupCounter","t","transforms","derivedType","undefined","transformNode","implicit","makeWithAncestors","filter","makeFromTransform","parsedAs","getWithExplicit","field","value","set","make","warn","message","invalidTransformIgnored","producedFields","parseData","outputNodes","outputNodeRefCounts","newData","clone","sequence","graticule","parseNothing","parse","makeExplicit","parentIsLayer","makeFromEncoding","length","implicitSelection","implicitEncoding","parseAll","parseAllForSortIndex","raw","makeOutputNode","Raw","agg","preFilterInvalid","dataSourcesForHandlingInvalidValues","markDef","mark","config","invalid","marks","scales","isPath","PreFilterInvalid","Main","postFilterInvalid","PostFilterInvalid","facetName","getName","facet","getSource","dataSourceType","getDataName","node"],"sources":["C:\\Users\\sutul\\node_modules\\vega-lite\\src\\compile\\data\\parse.ts"],"sourcesContent":["import {AncestorParse, DataComponent} from '.';\nimport {\n  Data,\n  isGenerator,\n  isGraticuleGenerator,\n  isInlineData,\n  isNamedData,\n  isSequenceGenerator,\n  isUrlData,\n  DataSourceType,\n  ParseValue\n} from '../../data';\nimport {getDataSourcesForHandlingInvalidValues, DataSourcesForHandlingInvalidValues} from '../invalid/datasources';\nimport * as log from '../../log';\nimport {isPathMark} from '../../mark';\nimport {\n  isAggregate,\n  isBin,\n  isCalculate,\n  isDensity,\n  isExtent,\n  isFilter,\n  isFlatten,\n  isFold,\n  isImpute,\n  isJoinAggregate,\n  isLoess,\n  isLookup,\n  isPivot,\n  isQuantile,\n  isRegression,\n  isSample,\n  isStack,\n  isTimeUnit,\n  isWindow\n} from '../../transform';\nimport {deepEqual, mergeDeep} from '../../util';\nimport {getMarkPropOrConfig} from '../common';\nimport {isFacetModel, isLayerModel, isUnitModel, Model} from '../model';\nimport {requiresSelectionId} from '../selection';\nimport {materializeSelections} from '../selection/parse';\nimport {AggregateNode} from './aggregate';\nimport {BinNode} from './bin';\nimport {CalculateNode} from './calculate';\nimport {DataFlowNode, OutputNode} from './dataflow';\nimport {DensityTransformNode} from './density';\nimport {ExtentTransformNode} from './extent';\nimport {FacetNode} from './facet';\nimport {FilterNode} from './filter';\nimport {FilterInvalidNode} from './filterinvalid';\nimport {FlattenTransformNode} from './flatten';\nimport {FoldTransformNode} from './fold';\nimport {\n  getImplicitFromEncoding,\n  getImplicitFromFilterTransform,\n  getImplicitFromSelection,\n  ParseNode\n} from './formatparse';\nimport {GeoJSONNode} from './geojson';\nimport {GeoPointNode} from './geopoint';\nimport {GraticuleNode} from './graticule';\nimport {IdentifierNode} from './identifier';\nimport {ImputeNode} from './impute';\nimport {JoinAggregateTransformNode} from './joinaggregate';\nimport {makeJoinAggregateFromFacet} from './joinaggregatefacet';\nimport {LoessTransformNode} from './loess';\nimport {LookupNode} from './lookup';\nimport {PivotTransformNode} from './pivot';\nimport {QuantileTransformNode} from './quantile';\nimport {RegressionTransformNode} from './regression';\nimport {SampleTransformNode} from './sample';\nimport {SequenceNode} from './sequence';\nimport {SourceNode} from './source';\nimport {StackNode} from './stack';\nimport {TimeUnitNode} from './timeunit';\nimport {WindowTransformNode} from './window';\n\nexport function findSource(data: Data, sources: SourceNode[]) {\n  for (const other of sources) {\n    const otherData = other.data;\n\n    // if both datasets have a name defined, we cannot merge\n    if (data.name && other.hasName() && data.name !== other.dataName) {\n      continue;\n    }\n\n    const formatMesh = (data as any).format?.mesh;\n    const otherFeature = otherData.format?.feature;\n\n    // feature and mesh are mutually exclusive\n    if (formatMesh && otherFeature) {\n      continue;\n    }\n\n    // we have to extract the same feature or mesh\n    const formatFeature = (data as any).format?.feature;\n    if ((formatFeature || otherFeature) && formatFeature !== otherFeature) {\n      continue;\n    }\n\n    const otherMesh = otherData.format?.mesh;\n    if ((formatMesh || otherMesh) && formatMesh !== otherMesh) {\n      continue;\n    }\n\n    if (isInlineData(data) && isInlineData(otherData)) {\n      if (deepEqual(data.values, otherData.values)) {\n        return other;\n      }\n    } else if (isUrlData(data) && isUrlData(otherData)) {\n      if (data.url === otherData.url) {\n        return other;\n      }\n    } else if (isNamedData(data)) {\n      if (data.name === other.dataName) {\n        return other;\n      }\n    }\n  }\n  return null;\n}\n\nfunction parseRoot(model: Model, sources: SourceNode[]): DataFlowNode {\n  if (model.data || !model.parent) {\n    // if the model defines a data source or is the root, create a source node\n\n    if (model.data === null) {\n      // data: null means we should ignore the parent's data so we just create a new data source\n      const source = new SourceNode({values: []});\n      sources.push(source);\n      return source;\n    }\n\n    const existingSource = findSource(model.data, sources);\n\n    if (existingSource) {\n      if (!isGenerator(model.data)) {\n        existingSource.data.format = mergeDeep({}, model.data.format, existingSource.data.format);\n      }\n\n      // if the new source has a name but the existing one does not, we can set it\n      if (!existingSource.hasName() && model.data.name) {\n        existingSource.dataName = model.data.name;\n      }\n\n      return existingSource;\n    } else {\n      const source = new SourceNode(model.data);\n      sources.push(source);\n      return source;\n    }\n  } else {\n    // If we don't have a source defined (overriding parent's data), use the parent's facet root or main.\n    return model.parent.component.data.facetRoot\n      ? model.parent.component.data.facetRoot\n      : model.parent.component.data.main;\n  }\n}\n\n/**\n * Parses a transform array into a chain of connected dataflow nodes.\n */\nexport function parseTransformArray(head: DataFlowNode, model: Model, ancestorParse: AncestorParse): DataFlowNode {\n  let lookupCounter = 0;\n\n  for (const t of model.transforms) {\n    let derivedType: ParseValue = undefined;\n    let transformNode: DataFlowNode;\n\n    if (isCalculate(t)) {\n      transformNode = head = new CalculateNode(head, t);\n      derivedType = 'derived';\n    } else if (isFilter(t)) {\n      const implicit = getImplicitFromFilterTransform(t);\n      transformNode = head = ParseNode.makeWithAncestors(head, {}, implicit, ancestorParse) ?? head;\n\n      head = new FilterNode(head, model, t.filter);\n    } else if (isBin(t)) {\n      transformNode = head = BinNode.makeFromTransform(head, t, model);\n      derivedType = 'number';\n    } else if (isTimeUnit(t)) {\n      derivedType = 'date';\n      const parsedAs = ancestorParse.getWithExplicit(t.field);\n      // Create parse node because the input to time unit is always date.\n      if (parsedAs.value === undefined) {\n        head = new ParseNode(head, {[t.field]: derivedType});\n        ancestorParse.set(t.field, derivedType, false);\n      }\n      transformNode = head = TimeUnitNode.makeFromTransform(head, t);\n    } else if (isAggregate(t)) {\n      transformNode = head = AggregateNode.makeFromTransform(head, t);\n      derivedType = 'number';\n      if (requiresSelectionId(model)) {\n        head = new IdentifierNode(head);\n      }\n    } else if (isLookup(t)) {\n      transformNode = head = LookupNode.make(head, model, t, lookupCounter++);\n      derivedType = 'derived';\n    } else if (isWindow(t)) {\n      transformNode = head = new WindowTransformNode(head, t);\n      derivedType = 'number';\n    } else if (isJoinAggregate(t)) {\n      transformNode = head = new JoinAggregateTransformNode(head, t);\n      derivedType = 'number';\n    } else if (isStack(t)) {\n      transformNode = head = StackNode.makeFromTransform(head, t);\n      derivedType = 'derived';\n    } else if (isFold(t)) {\n      transformNode = head = new FoldTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isExtent(t)) {\n      transformNode = head = new ExtentTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isFlatten(t)) {\n      transformNode = head = new FlattenTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isPivot(t)) {\n      transformNode = head = new PivotTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isSample(t)) {\n      head = new SampleTransformNode(head, t);\n    } else if (isImpute(t)) {\n      transformNode = head = ImputeNode.makeFromTransform(head, t);\n      derivedType = 'derived';\n    } else if (isDensity(t)) {\n      transformNode = head = new DensityTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isQuantile(t)) {\n      transformNode = head = new QuantileTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isRegression(t)) {\n      transformNode = head = new RegressionTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isLoess(t)) {\n      transformNode = head = new LoessTransformNode(head, t);\n      derivedType = 'derived';\n    } else {\n      log.warn(log.message.invalidTransformIgnored(t));\n      continue;\n    }\n\n    if (transformNode && derivedType !== undefined) {\n      for (const field of transformNode.producedFields() ?? []) {\n        ancestorParse.set(field, derivedType, false);\n      }\n    }\n  }\n\n  return head;\n}\n\n/*\nDescription of the dataflow (http://asciiflow.com/):\n     +--------+\n     | Source |\n     +---+----+\n         |\n         v\n     FormatParse\n     (explicit)\n         |\n         v\n     Transforms\n(Filter, Calculate, Binning, TimeUnit, Aggregate, Window, ...)\n         |\n         v\n     FormatParse\n     (implicit)\n         |\n         v\n Binning (in `encoding`)\n         |\n         v\n Timeunit (in `encoding`)\n         |\n         v\nFormula From Sort Array\n         |\n         v\n      +--+--+\n      | Raw |\n      +-----+\n         |\n         v\n  Aggregate (in `encoding`)\n         |\n         v\n  Stack (in `encoding`)\n         |\n         v\n+- - - - - - - - - - -+\n|   PreFilterInvalid  | - - - -> scale domains\n|(when scales need it)|\n+- - - - - - - - - - -+\n         |\n         v\n  Invalid Filter (if the main data source needs it)\n         |\n         v\n   +----------+\n   |   Main   | - - - -> scale domains\n   +----------+\n         |\n         v\n+- - - - - - - - - - -+\n|   PostFilterInvalid | - - - -> scale domains\n|(when scales need it)|\n+- - - - - - - - - - -+\n         |\n         v\n     +-------+\n     | Facet |----> \"column\", \"column-layout\", and \"row\"\n     +-------+\n         |\n         v\n  ...Child data...\n*/\n\nexport function parseData(model: Model): DataComponent {\n  let head = parseRoot(model, model.component.data.sources);\n\n  const {outputNodes, outputNodeRefCounts} = model.component.data;\n  const data = model.data;\n\n  const newData = data && (isGenerator(data) || isUrlData(data) || isInlineData(data));\n  const ancestorParse =\n    !newData && model.parent ? model.parent.component.data.ancestorParse.clone() : new AncestorParse();\n\n  if (isGenerator(data)) {\n    // insert generator transform\n    if (isSequenceGenerator(data)) {\n      head = new SequenceNode(head, data.sequence);\n    } else if (isGraticuleGenerator(data)) {\n      head = new GraticuleNode(head, data.graticule);\n    }\n    // no parsing necessary for generator\n    ancestorParse.parseNothing = true;\n  } else if (data?.format?.parse === null) {\n    // format.parse: null means disable parsing\n    ancestorParse.parseNothing = true;\n  }\n\n  head = ParseNode.makeExplicit(head, model, ancestorParse) ?? head;\n\n  // Default discrete selections require an identifer transform to\n  // uniquely identify data points. Add this transform at the head of\n  // the pipeline such that the identifier field is available for all\n  // subsequent datasets. During optimization, we will remove this\n  // transform if it proves to be unnecessary. Additional identifier\n  // transforms will be necessary when new tuples are constructed\n  // (e.g., post-aggregation).\n  head = new IdentifierNode(head);\n\n  // HACK: This is equivalent for merging bin extent for union scale.\n  // FIXME(https://github.com/vega/vega-lite/issues/2270): Correctly merge extent / bin node for shared bin scale\n  const parentIsLayer = model.parent && isLayerModel(model.parent);\n  if (isUnitModel(model) || isFacetModel(model)) {\n    if (parentIsLayer) {\n      head = BinNode.makeFromEncoding(head, model) ?? head;\n    }\n  }\n\n  if (model.transforms.length > 0) {\n    head = parseTransformArray(head, model, ancestorParse);\n  }\n\n  // create parse nodes for fields that need to be parsed (or flattened) implicitly\n  const implicitSelection = getImplicitFromSelection(model);\n  const implicitEncoding = getImplicitFromEncoding(model);\n  head = ParseNode.makeWithAncestors(head, {}, {...implicitSelection, ...implicitEncoding}, ancestorParse) ?? head;\n\n  if (isUnitModel(model)) {\n    head = GeoJSONNode.parseAll(head, model);\n    head = GeoPointNode.parseAll(head, model);\n  }\n\n  if (isUnitModel(model) || isFacetModel(model)) {\n    if (!parentIsLayer) {\n      head = BinNode.makeFromEncoding(head, model) ?? head;\n    }\n\n    head = TimeUnitNode.makeFromEncoding(head, model) ?? head;\n    head = CalculateNode.parseAllForSortIndex(head, model);\n  }\n\n  // add an output node pre aggregation\n  const raw = (head = makeOutputNode(DataSourceType.Raw, model, head));\n\n  if (isUnitModel(model)) {\n    const agg = AggregateNode.makeFromEncoding(head, model);\n    if (agg) {\n      head = agg;\n\n      if (requiresSelectionId(model)) {\n        head = new IdentifierNode(head);\n      }\n    }\n    head = ImputeNode.makeFromEncoding(head, model) ?? head;\n    head = StackNode.makeFromEncoding(head, model) ?? head;\n  }\n\n  let preFilterInvalid: OutputNode | undefined;\n  let dataSourcesForHandlingInvalidValues: DataSourcesForHandlingInvalidValues | undefined;\n  if (isUnitModel(model)) {\n    const {markDef, mark, config} = model;\n    const invalid = getMarkPropOrConfig('invalid', markDef, config);\n\n    const {marks, scales} = (dataSourcesForHandlingInvalidValues = getDataSourcesForHandlingInvalidValues({\n      invalid,\n      isPath: isPathMark(mark)\n    }));\n\n    if (marks !== scales && scales === 'include-invalid-values') {\n      // Create a seperate preFilterInvalid dataSource if scales need pre-filter data but marks needs post-filter.\n      preFilterInvalid = head = makeOutputNode(DataSourceType.PreFilterInvalid, model, head);\n    }\n\n    if (marks === 'exclude-invalid-values') {\n      head = FilterInvalidNode.make(head, model, dataSourcesForHandlingInvalidValues) ?? head;\n    }\n  }\n\n  // output \"main\" node for marks\n  const main = (head = makeOutputNode(DataSourceType.Main, model, head));\n\n  let postFilterInvalid: OutputNode | undefined;\n  if (isUnitModel(model) && dataSourcesForHandlingInvalidValues) {\n    const {marks, scales} = dataSourcesForHandlingInvalidValues;\n    if (marks === 'include-invalid-values' && scales === 'exclude-invalid-values') {\n      // Create a seperate postFilterInvalid dataSource if scales need post-filter data but marks needs pre-filter.\n      head = FilterInvalidNode.make(head, model, dataSourcesForHandlingInvalidValues) ?? head;\n\n      postFilterInvalid = head = makeOutputNode(DataSourceType.PostFilterInvalid, model, head);\n    }\n  }\n\n  if (isUnitModel(model)) {\n    materializeSelections(model, main);\n  }\n\n  // add facet marker\n  let facetRoot = null;\n  if (isFacetModel(model)) {\n    const facetName = model.getName('facet');\n\n    // Derive new aggregate for facet's sort field\n    // augment data source with new fields for crossed facet\n    head = makeJoinAggregateFromFacet(head, model.facet) ?? head;\n\n    facetRoot = new FacetNode(head, model, facetName, main.getSource());\n    outputNodes[facetName] = facetRoot;\n  }\n\n  return {\n    ...model.component.data,\n    outputNodes,\n    outputNodeRefCounts,\n    raw,\n    main,\n    facetRoot,\n    ancestorParse,\n    preFilterInvalid,\n    postFilterInvalid\n  };\n}\n\nfunction makeOutputNode(dataSourceType: DataSourceType, model: Model, head: DataFlowNode) {\n  const {outputNodes, outputNodeRefCounts} = model.component.data;\n  const name = model.getDataName(dataSourceType);\n  const node = new OutputNode(head, name, dataSourceType, outputNodeRefCounts);\n  outputNodes[name] = node;\n  return node;\n}\n"],"mappings":"AAAA,SAAQA,aAAa,QAAsB,GAAG;AAC9C,SAEEC,WAAW,EACXC,oBAAoB,EACpBC,YAAY,EACZC,WAAW,EACXC,mBAAmB,EACnBC,SAAS,EACTC,cAAc,QAET,YAAY;AACnB,SAAQC,sCAAsC,QAA4C,wBAAwB;AAClH,OAAO,KAAKC,GAAG,MAAM,WAAW;AAChC,SAAQC,UAAU,QAAO,YAAY;AACrC,SACEC,WAAW,EACXC,KAAK,EACLC,WAAW,EACXC,SAAS,EACTC,QAAQ,EACRC,QAAQ,EACRC,SAAS,EACTC,MAAM,EACNC,QAAQ,EACRC,eAAe,EACfC,OAAO,EACPC,QAAQ,EACRC,OAAO,EACPC,UAAU,EACVC,YAAY,EACZC,QAAQ,EACRC,OAAO,EACPC,UAAU,EACVC,QAAQ,QACH,iBAAiB;AACxB,SAAQC,SAAS,EAAEC,SAAS,QAAO,YAAY;AAC/C,SAAQC,mBAAmB,QAAO,WAAW;AAC7C,SAAQC,YAAY,EAAEC,YAAY,EAAEC,WAAW,QAAc,UAAU;AACvE,SAAQC,mBAAmB,QAAO,cAAc;AAChD,SAAQC,qBAAqB,QAAO,oBAAoB;AACxD,SAAQC,aAAa,QAAO,aAAa;AACzC,SAAQC,OAAO,QAAO,OAAO;AAC7B,SAAQC,aAAa,QAAO,aAAa;AACzC,SAAsBC,UAAU,QAAO,YAAY;AACnD,SAAQC,oBAAoB,QAAO,WAAW;AAC9C,SAAQC,mBAAmB,QAAO,UAAU;AAC5C,SAAQC,SAAS,QAAO,SAAS;AACjC,SAAQC,UAAU,QAAO,UAAU;AACnC,SAAQC,iBAAiB,QAAO,iBAAiB;AACjD,SAAQC,oBAAoB,QAAO,WAAW;AAC9C,SAAQC,iBAAiB,QAAO,QAAQ;AACxC,SACEC,uBAAuB,EACvBC,8BAA8B,EAC9BC,wBAAwB,EACxBC,SAAS,QACJ,eAAe;AACtB,SAAQC,WAAW,QAAO,WAAW;AACrC,SAAQC,YAAY,QAAO,YAAY;AACvC,SAAQC,aAAa,QAAO,aAAa;AACzC,SAAQC,cAAc,QAAO,cAAc;AAC3C,SAAQC,UAAU,QAAO,UAAU;AACnC,SAAQC,0BAA0B,QAAO,iBAAiB;AAC1D,SAAQC,0BAA0B,QAAO,sBAAsB;AAC/D,SAAQC,kBAAkB,QAAO,SAAS;AAC1C,SAAQC,UAAU,QAAO,UAAU;AACnC,SAAQC,kBAAkB,QAAO,SAAS;AAC1C,SAAQC,qBAAqB,QAAO,YAAY;AAChD,SAAQC,uBAAuB,QAAO,cAAc;AACpD,SAAQC,mBAAmB,QAAO,UAAU;AAC5C,SAAQC,YAAY,QAAO,YAAY;AACvC,SAAQC,UAAU,QAAO,UAAU;AACnC,SAAQC,SAAS,QAAO,SAAS;AACjC,SAAQC,YAAY,QAAO,YAAY;AACvC,SAAQC,mBAAmB,QAAO,UAAU;AAE5C,OAAM,SAAUC,UAAUA,CAACC,IAAU,EAAEC,OAAqB;EAC1D,KAAK,MAAMC,KAAK,IAAID,OAAO,EAAE;IAC3B,MAAME,SAAS,GAAGD,KAAK,CAACF,IAAI;IAE5B;IACA,IAAIA,IAAI,CAACI,IAAI,IAAIF,KAAK,CAACG,OAAO,EAAE,IAAIL,IAAI,CAACI,IAAI,KAAKF,KAAK,CAACI,QAAQ,EAAE;MAChE;IACF;IAEA,MAAMC,UAAU,GAAIP,IAAY,CAACQ,MAAM,EAAEC,IAAI;IAC7C,MAAMC,YAAY,GAAGP,SAAS,CAACK,MAAM,EAAEG,OAAO;IAE9C;IACA,IAAIJ,UAAU,IAAIG,YAAY,EAAE;MAC9B;IACF;IAEA;IACA,MAAME,aAAa,GAAIZ,IAAY,CAACQ,MAAM,EAAEG,OAAO;IACnD,IAAI,CAACC,aAAa,IAAIF,YAAY,KAAKE,aAAa,KAAKF,YAAY,EAAE;MACrE;IACF;IAEA,MAAMG,SAAS,GAAGV,SAAS,CAACK,MAAM,EAAEC,IAAI;IACxC,IAAI,CAACF,UAAU,IAAIM,SAAS,KAAKN,UAAU,KAAKM,SAAS,EAAE;MACzD;IACF;IAEA,IAAIlF,YAAY,CAACqE,IAAI,CAAC,IAAIrE,YAAY,CAACwE,SAAS,CAAC,EAAE;MACjD,IAAI7C,SAAS,CAAC0C,IAAI,CAACc,MAAM,EAAEX,SAAS,CAACW,MAAM,CAAC,EAAE;QAC5C,OAAOZ,KAAK;MACd;IACF,CAAC,MAAM,IAAIpE,SAAS,CAACkE,IAAI,CAAC,IAAIlE,SAAS,CAACqE,SAAS,CAAC,EAAE;MAClD,IAAIH,IAAI,CAACe,GAAG,KAAKZ,SAAS,CAACY,GAAG,EAAE;QAC9B,OAAOb,KAAK;MACd;IACF,CAAC,MAAM,IAAItE,WAAW,CAACoE,IAAI,CAAC,EAAE;MAC5B,IAAIA,IAAI,CAACI,IAAI,KAAKF,KAAK,CAACI,QAAQ,EAAE;QAChC,OAAOJ,KAAK;MACd;IACF;EACF;EACA,OAAO,IAAI;AACb;AAEA,SAASc,SAASA,CAACC,KAAY,EAAEhB,OAAqB;EACpD,IAAIgB,KAAK,CAACjB,IAAI,IAAI,CAACiB,KAAK,CAACC,MAAM,EAAE;IAC/B;IAEA,IAAID,KAAK,CAACjB,IAAI,KAAK,IAAI,EAAE;MACvB;MACA,MAAMmB,MAAM,GAAG,IAAIxB,UAAU,CAAC;QAACmB,MAAM,EAAE;MAAE,CAAC,CAAC;MAC3Cb,OAAO,CAACmB,IAAI,CAACD,MAAM,CAAC;MACpB,OAAOA,MAAM;IACf;IAEA,MAAME,cAAc,GAAGtB,UAAU,CAACkB,KAAK,CAACjB,IAAI,EAAEC,OAAO,CAAC;IAEtD,IAAIoB,cAAc,EAAE;MAClB,IAAI,CAAC5F,WAAW,CAACwF,KAAK,CAACjB,IAAI,CAAC,EAAE;QAC5BqB,cAAc,CAACrB,IAAI,CAACQ,MAAM,GAAGjD,SAAS,CAAC,EAAE,EAAE0D,KAAK,CAACjB,IAAI,CAACQ,MAAM,EAAEa,cAAc,CAACrB,IAAI,CAACQ,MAAM,CAAC;MAC3F;MAEA;MACA,IAAI,CAACa,cAAc,CAAChB,OAAO,EAAE,IAAIY,KAAK,CAACjB,IAAI,CAACI,IAAI,EAAE;QAChDiB,cAAc,CAACf,QAAQ,GAAGW,KAAK,CAACjB,IAAI,CAACI,IAAI;MAC3C;MAEA,OAAOiB,cAAc;IACvB,CAAC,MAAM;MACL,MAAMF,MAAM,GAAG,IAAIxB,UAAU,CAACsB,KAAK,CAACjB,IAAI,CAAC;MACzCC,OAAO,CAACmB,IAAI,CAACD,MAAM,CAAC;MACpB,OAAOA,MAAM;IACf;EACF,CAAC,MAAM;IACL;IACA,OAAOF,KAAK,CAACC,MAAM,CAACI,SAAS,CAACtB,IAAI,CAACuB,SAAS,GACxCN,KAAK,CAACC,MAAM,CAACI,SAAS,CAACtB,IAAI,CAACuB,SAAS,GACrCN,KAAK,CAACC,MAAM,CAACI,SAAS,CAACtB,IAAI,CAACwB,IAAI;EACtC;AACF;AAEA;;;AAGA,OAAM,SAAUC,mBAAmBA,CAACC,IAAkB,EAAET,KAAY,EAAEU,aAA4B;EAChG,IAAIC,aAAa,GAAG,CAAC;EAErB,KAAK,MAAMC,CAAC,IAAIZ,KAAK,CAACa,UAAU,EAAE;IAChC,IAAIC,WAAW,GAAeC,SAAS;IACvC,IAAIC,aAA2B;IAE/B,IAAI5F,WAAW,CAACwF,CAAC,CAAC,EAAE;MAClBI,aAAa,GAAGP,IAAI,GAAG,IAAI1D,aAAa,CAAC0D,IAAI,EAAEG,CAAC,CAAC;MACjDE,WAAW,GAAG,SAAS;IACzB,CAAC,MAAM,IAAIvF,QAAQ,CAACqF,CAAC,CAAC,EAAE;MACtB,MAAMK,QAAQ,GAAGxD,8BAA8B,CAACmD,CAAC,CAAC;MAClDI,aAAa,GAAGP,IAAI,GAAG9C,SAAS,CAACuD,iBAAiB,CAACT,IAAI,EAAE,EAAE,EAAEQ,QAAQ,EAAEP,aAAa,CAAC,IAAID,IAAI;MAE7FA,IAAI,GAAG,IAAIrD,UAAU,CAACqD,IAAI,EAAET,KAAK,EAAEY,CAAC,CAACO,MAAM,CAAC;IAC9C,CAAC,MAAM,IAAIhG,KAAK,CAACyF,CAAC,CAAC,EAAE;MACnBI,aAAa,GAAGP,IAAI,GAAG3D,OAAO,CAACsE,iBAAiB,CAACX,IAAI,EAAEG,CAAC,EAAEZ,KAAK,CAAC;MAChEc,WAAW,GAAG,QAAQ;IACxB,CAAC,MAAM,IAAI3E,UAAU,CAACyE,CAAC,CAAC,EAAE;MACxBE,WAAW,GAAG,MAAM;MACpB,MAAMO,QAAQ,GAAGX,aAAa,CAACY,eAAe,CAACV,CAAC,CAACW,KAAK,CAAC;MACvD;MACA,IAAIF,QAAQ,CAACG,KAAK,KAAKT,SAAS,EAAE;QAChCN,IAAI,GAAG,IAAI9C,SAAS,CAAC8C,IAAI,EAAE;UAAC,CAACG,CAAC,CAACW,KAAK,GAAGT;QAAW,CAAC,CAAC;QACpDJ,aAAa,CAACe,GAAG,CAACb,CAAC,CAACW,KAAK,EAAET,WAAW,EAAE,KAAK,CAAC;MAChD;MACAE,aAAa,GAAGP,IAAI,GAAG7B,YAAY,CAACwC,iBAAiB,CAACX,IAAI,EAAEG,CAAC,CAAC;IAChE,CAAC,MAAM,IAAI1F,WAAW,CAAC0F,CAAC,CAAC,EAAE;MACzBI,aAAa,GAAGP,IAAI,GAAG5D,aAAa,CAACuE,iBAAiB,CAACX,IAAI,EAAEG,CAAC,CAAC;MAC/DE,WAAW,GAAG,QAAQ;MACtB,IAAInE,mBAAmB,CAACqD,KAAK,CAAC,EAAE;QAC9BS,IAAI,GAAG,IAAI1C,cAAc,CAAC0C,IAAI,CAAC;MACjC;IACF,CAAC,MAAM,IAAI5E,QAAQ,CAAC+E,CAAC,CAAC,EAAE;MACtBI,aAAa,GAAGP,IAAI,GAAGrC,UAAU,CAACsD,IAAI,CAACjB,IAAI,EAAET,KAAK,EAAEY,CAAC,EAAED,aAAa,EAAE,CAAC;MACvEG,WAAW,GAAG,SAAS;IACzB,CAAC,MAAM,IAAI1E,QAAQ,CAACwE,CAAC,CAAC,EAAE;MACtBI,aAAa,GAAGP,IAAI,GAAG,IAAI5B,mBAAmB,CAAC4B,IAAI,EAAEG,CAAC,CAAC;MACvDE,WAAW,GAAG,QAAQ;IACxB,CAAC,MAAM,IAAInF,eAAe,CAACiF,CAAC,CAAC,EAAE;MAC7BI,aAAa,GAAGP,IAAI,GAAG,IAAIxC,0BAA0B,CAACwC,IAAI,EAAEG,CAAC,CAAC;MAC9DE,WAAW,GAAG,QAAQ;IACxB,CAAC,MAAM,IAAI5E,OAAO,CAAC0E,CAAC,CAAC,EAAE;MACrBI,aAAa,GAAGP,IAAI,GAAG9B,SAAS,CAACyC,iBAAiB,CAACX,IAAI,EAAEG,CAAC,CAAC;MAC3DE,WAAW,GAAG,SAAS;IACzB,CAAC,MAAM,IAAIrF,MAAM,CAACmF,CAAC,CAAC,EAAE;MACpBI,aAAa,GAAGP,IAAI,GAAG,IAAIlD,iBAAiB,CAACkD,IAAI,EAAEG,CAAC,CAAC;MACrDE,WAAW,GAAG,SAAS;IACzB,CAAC,MAAM,IAAIxF,QAAQ,CAACsF,CAAC,CAAC,EAAE;MACtBI,aAAa,GAAGP,IAAI,GAAG,IAAIvD,mBAAmB,CAACuD,IAAI,EAAEG,CAAC,CAAC;MACvDE,WAAW,GAAG,SAAS;IACzB,CAAC,MAAM,IAAItF,SAAS,CAACoF,CAAC,CAAC,EAAE;MACvBI,aAAa,GAAGP,IAAI,GAAG,IAAInD,oBAAoB,CAACmD,IAAI,EAAEG,CAAC,CAAC;MACxDE,WAAW,GAAG,SAAS;IACzB,CAAC,MAAM,IAAIhF,OAAO,CAAC8E,CAAC,CAAC,EAAE;MACrBI,aAAa,GAAGP,IAAI,GAAG,IAAIpC,kBAAkB,CAACoC,IAAI,EAAEG,CAAC,CAAC;MACtDE,WAAW,GAAG,SAAS;IACzB,CAAC,MAAM,IAAI7E,QAAQ,CAAC2E,CAAC,CAAC,EAAE;MACtBH,IAAI,GAAG,IAAIjC,mBAAmB,CAACiC,IAAI,EAAEG,CAAC,CAAC;IACzC,CAAC,MAAM,IAAIlF,QAAQ,CAACkF,CAAC,CAAC,EAAE;MACtBI,aAAa,GAAGP,IAAI,GAAGzC,UAAU,CAACoD,iBAAiB,CAACX,IAAI,EAAEG,CAAC,CAAC;MAC5DE,WAAW,GAAG,SAAS;IACzB,CAAC,MAAM,IAAIzF,SAAS,CAACuF,CAAC,CAAC,EAAE;MACvBI,aAAa,GAAGP,IAAI,GAAG,IAAIxD,oBAAoB,CAACwD,IAAI,EAAEG,CAAC,CAAC;MACxDE,WAAW,GAAG,SAAS;IACzB,CAAC,MAAM,IAAI/E,UAAU,CAAC6E,CAAC,CAAC,EAAE;MACxBI,aAAa,GAAGP,IAAI,GAAG,IAAInC,qBAAqB,CAACmC,IAAI,EAAEG,CAAC,CAAC;MACzDE,WAAW,GAAG,SAAS;IACzB,CAAC,MAAM,IAAI9E,YAAY,CAAC4E,CAAC,CAAC,EAAE;MAC1BI,aAAa,GAAGP,IAAI,GAAG,IAAIlC,uBAAuB,CAACkC,IAAI,EAAEG,CAAC,CAAC;MAC3DE,WAAW,GAAG,SAAS;IACzB,CAAC,MAAM,IAAIlF,OAAO,CAACgF,CAAC,CAAC,EAAE;MACrBI,aAAa,GAAGP,IAAI,GAAG,IAAItC,kBAAkB,CAACsC,IAAI,EAAEG,CAAC,CAAC;MACtDE,WAAW,GAAG,SAAS;IACzB,CAAC,MAAM;MACL9F,GAAG,CAAC2G,IAAI,CAAC3G,GAAG,CAAC4G,OAAO,CAACC,uBAAuB,CAACjB,CAAC,CAAC,CAAC;MAChD;IACF;IAEA,IAAII,aAAa,IAAIF,WAAW,KAAKC,SAAS,EAAE;MAC9C,KAAK,MAAMQ,KAAK,IAAIP,aAAa,CAACc,cAAc,EAAE,IAAI,EAAE,EAAE;QACxDpB,aAAa,CAACe,GAAG,CAACF,KAAK,EAAET,WAAW,EAAE,KAAK,CAAC;MAC9C;IACF;EACF;EAEA,OAAOL,IAAI;AACb;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAmEA,OAAM,SAAUsB,SAASA,CAAC/B,KAAY;EACpC,IAAIS,IAAI,GAAGV,SAAS,CAACC,KAAK,EAAEA,KAAK,CAACK,SAAS,CAACtB,IAAI,CAACC,OAAO,CAAC;EAEzD,MAAM;IAACgD,WAAW;IAAEC;EAAmB,CAAC,GAAGjC,KAAK,CAACK,SAAS,CAACtB,IAAI;EAC/D,MAAMA,IAAI,GAAGiB,KAAK,CAACjB,IAAI;EAEvB,MAAMmD,OAAO,GAAGnD,IAAI,KAAKvE,WAAW,CAACuE,IAAI,CAAC,IAAIlE,SAAS,CAACkE,IAAI,CAAC,IAAIrE,YAAY,CAACqE,IAAI,CAAC,CAAC;EACpF,MAAM2B,aAAa,GACjB,CAACwB,OAAO,IAAIlC,KAAK,CAACC,MAAM,GAAGD,KAAK,CAACC,MAAM,CAACI,SAAS,CAACtB,IAAI,CAAC2B,aAAa,CAACyB,KAAK,EAAE,GAAG,IAAI5H,aAAa,EAAE;EAEpG,IAAIC,WAAW,CAACuE,IAAI,CAAC,EAAE;IACrB;IACA,IAAInE,mBAAmB,CAACmE,IAAI,CAAC,EAAE;MAC7B0B,IAAI,GAAG,IAAIhC,YAAY,CAACgC,IAAI,EAAE1B,IAAI,CAACqD,QAAQ,CAAC;IAC9C,CAAC,MAAM,IAAI3H,oBAAoB,CAACsE,IAAI,CAAC,EAAE;MACrC0B,IAAI,GAAG,IAAI3C,aAAa,CAAC2C,IAAI,EAAE1B,IAAI,CAACsD,SAAS,CAAC;IAChD;IACA;IACA3B,aAAa,CAAC4B,YAAY,GAAG,IAAI;EACnC,CAAC,MAAM,IAAIvD,IAAI,EAAEQ,MAAM,EAAEgD,KAAK,KAAK,IAAI,EAAE;IACvC;IACA7B,aAAa,CAAC4B,YAAY,GAAG,IAAI;EACnC;EAEA7B,IAAI,GAAG9C,SAAS,CAAC6E,YAAY,CAAC/B,IAAI,EAAET,KAAK,EAAEU,aAAa,CAAC,IAAID,IAAI;EAEjE;EACA;EACA;EACA;EACA;EACA;EACA;EACAA,IAAI,GAAG,IAAI1C,cAAc,CAAC0C,IAAI,CAAC;EAE/B;EACA;EACA,MAAMgC,aAAa,GAAGzC,KAAK,CAACC,MAAM,IAAIxD,YAAY,CAACuD,KAAK,CAACC,MAAM,CAAC;EAChE,IAAIvD,WAAW,CAACsD,KAAK,CAAC,IAAIxD,YAAY,CAACwD,KAAK,CAAC,EAAE;IAC7C,IAAIyC,aAAa,EAAE;MACjBhC,IAAI,GAAG3D,OAAO,CAAC4F,gBAAgB,CAACjC,IAAI,EAAET,KAAK,CAAC,IAAIS,IAAI;IACtD;EACF;EAEA,IAAIT,KAAK,CAACa,UAAU,CAAC8B,MAAM,GAAG,CAAC,EAAE;IAC/BlC,IAAI,GAAGD,mBAAmB,CAACC,IAAI,EAAET,KAAK,EAAEU,aAAa,CAAC;EACxD;EAEA;EACA,MAAMkC,iBAAiB,GAAGlF,wBAAwB,CAACsC,KAAK,CAAC;EACzD,MAAM6C,gBAAgB,GAAGrF,uBAAuB,CAACwC,KAAK,CAAC;EACvDS,IAAI,GAAG9C,SAAS,CAACuD,iBAAiB,CAACT,IAAI,EAAE,EAAE,EAAE;IAAC,GAAGmC,iBAAiB;IAAE,GAAGC;EAAgB,CAAC,EAAEnC,aAAa,CAAC,IAAID,IAAI;EAEhH,IAAI/D,WAAW,CAACsD,KAAK,CAAC,EAAE;IACtBS,IAAI,GAAG7C,WAAW,CAACkF,QAAQ,CAACrC,IAAI,EAAET,KAAK,CAAC;IACxCS,IAAI,GAAG5C,YAAY,CAACiF,QAAQ,CAACrC,IAAI,EAAET,KAAK,CAAC;EAC3C;EAEA,IAAItD,WAAW,CAACsD,KAAK,CAAC,IAAIxD,YAAY,CAACwD,KAAK,CAAC,EAAE;IAC7C,IAAI,CAACyC,aAAa,EAAE;MAClBhC,IAAI,GAAG3D,OAAO,CAAC4F,gBAAgB,CAACjC,IAAI,EAAET,KAAK,CAAC,IAAIS,IAAI;IACtD;IAEAA,IAAI,GAAG7B,YAAY,CAAC8D,gBAAgB,CAACjC,IAAI,EAAET,KAAK,CAAC,IAAIS,IAAI;IACzDA,IAAI,GAAG1D,aAAa,CAACgG,oBAAoB,CAACtC,IAAI,EAAET,KAAK,CAAC;EACxD;EAEA;EACA,MAAMgD,GAAG,GAAIvC,IAAI,GAAGwC,cAAc,CAACnI,cAAc,CAACoI,GAAG,EAAElD,KAAK,EAAES,IAAI,CAAE;EAEpE,IAAI/D,WAAW,CAACsD,KAAK,CAAC,EAAE;IACtB,MAAMmD,GAAG,GAAGtG,aAAa,CAAC6F,gBAAgB,CAACjC,IAAI,EAAET,KAAK,CAAC;IACvD,IAAImD,GAAG,EAAE;MACP1C,IAAI,GAAG0C,GAAG;MAEV,IAAIxG,mBAAmB,CAACqD,KAAK,CAAC,EAAE;QAC9BS,IAAI,GAAG,IAAI1C,cAAc,CAAC0C,IAAI,CAAC;MACjC;IACF;IACAA,IAAI,GAAGzC,UAAU,CAAC0E,gBAAgB,CAACjC,IAAI,EAAET,KAAK,CAAC,IAAIS,IAAI;IACvDA,IAAI,GAAG9B,SAAS,CAAC+D,gBAAgB,CAACjC,IAAI,EAAET,KAAK,CAAC,IAAIS,IAAI;EACxD;EAEA,IAAI2C,gBAAwC;EAC5C,IAAIC,mCAAoF;EACxF,IAAI3G,WAAW,CAACsD,KAAK,CAAC,EAAE;IACtB,MAAM;MAACsD,OAAO;MAAEC,IAAI;MAAEC;IAAM,CAAC,GAAGxD,KAAK;IACrC,MAAMyD,OAAO,GAAGlH,mBAAmB,CAAC,SAAS,EAAE+G,OAAO,EAAEE,MAAM,CAAC;IAE/D,MAAM;MAACE,KAAK;MAAEC;IAAM,CAAC,GAAIN,mCAAmC,GAAGtI,sCAAsC,CAAC;MACpG0I,OAAO;MACPG,MAAM,EAAE3I,UAAU,CAACsI,IAAI;KACxB,CAAE;IAEH,IAAIG,KAAK,KAAKC,MAAM,IAAIA,MAAM,KAAK,wBAAwB,EAAE;MAC3D;MACAP,gBAAgB,GAAG3C,IAAI,GAAGwC,cAAc,CAACnI,cAAc,CAAC+I,gBAAgB,EAAE7D,KAAK,EAAES,IAAI,CAAC;IACxF;IAEA,IAAIiD,KAAK,KAAK,wBAAwB,EAAE;MACtCjD,IAAI,GAAGpD,iBAAiB,CAACqE,IAAI,CAACjB,IAAI,EAAET,KAAK,EAAEqD,mCAAmC,CAAC,IAAI5C,IAAI;IACzF;EACF;EAEA;EACA,MAAMF,IAAI,GAAIE,IAAI,GAAGwC,cAAc,CAACnI,cAAc,CAACgJ,IAAI,EAAE9D,KAAK,EAAES,IAAI,CAAE;EAEtE,IAAIsD,iBAAyC;EAC7C,IAAIrH,WAAW,CAACsD,KAAK,CAAC,IAAIqD,mCAAmC,EAAE;IAC7D,MAAM;MAACK,KAAK;MAAEC;IAAM,CAAC,GAAGN,mCAAmC;IAC3D,IAAIK,KAAK,KAAK,wBAAwB,IAAIC,MAAM,KAAK,wBAAwB,EAAE;MAC7E;MACAlD,IAAI,GAAGpD,iBAAiB,CAACqE,IAAI,CAACjB,IAAI,EAAET,KAAK,EAAEqD,mCAAmC,CAAC,IAAI5C,IAAI;MAEvFsD,iBAAiB,GAAGtD,IAAI,GAAGwC,cAAc,CAACnI,cAAc,CAACkJ,iBAAiB,EAAEhE,KAAK,EAAES,IAAI,CAAC;IAC1F;EACF;EAEA,IAAI/D,WAAW,CAACsD,KAAK,CAAC,EAAE;IACtBpD,qBAAqB,CAACoD,KAAK,EAAEO,IAAI,CAAC;EACpC;EAEA;EACA,IAAID,SAAS,GAAG,IAAI;EACpB,IAAI9D,YAAY,CAACwD,KAAK,CAAC,EAAE;IACvB,MAAMiE,SAAS,GAAGjE,KAAK,CAACkE,OAAO,CAAC,OAAO,CAAC;IAExC;IACA;IACAzD,IAAI,GAAGvC,0BAA0B,CAACuC,IAAI,EAAET,KAAK,CAACmE,KAAK,CAAC,IAAI1D,IAAI;IAE5DH,SAAS,GAAG,IAAInD,SAAS,CAACsD,IAAI,EAAET,KAAK,EAAEiE,SAAS,EAAE1D,IAAI,CAAC6D,SAAS,EAAE,CAAC;IACnEpC,WAAW,CAACiC,SAAS,CAAC,GAAG3D,SAAS;EACpC;EAEA,OAAO;IACL,GAAGN,KAAK,CAACK,SAAS,CAACtB,IAAI;IACvBiD,WAAW;IACXC,mBAAmB;IACnBe,GAAG;IACHzC,IAAI;IACJD,SAAS;IACTI,aAAa;IACb0C,gBAAgB;IAChBW;GACD;AACH;AAEA,SAASd,cAAcA,CAACoB,cAA8B,EAAErE,KAAY,EAAES,IAAkB;EACtF,MAAM;IAACuB,WAAW;IAAEC;EAAmB,CAAC,GAAGjC,KAAK,CAACK,SAAS,CAACtB,IAAI;EAC/D,MAAMI,IAAI,GAAGa,KAAK,CAACsE,WAAW,CAACD,cAAc,CAAC;EAC9C,MAAME,IAAI,GAAG,IAAIvH,UAAU,CAACyD,IAAI,EAAEtB,IAAI,EAAEkF,cAAc,EAAEpC,mBAAmB,CAAC;EAC5ED,WAAW,CAAC7C,IAAI,CAAC,GAAGoF,IAAI;EACxB,OAAOA,IAAI;AACb","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}